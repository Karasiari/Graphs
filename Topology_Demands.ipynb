{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/Karasiari/Graphs/blob/main/Topology.ipynb",
      "authorship_tag": "ABX9TyO0IrQERGqcfPcab3auBaa3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karasiari/Graphs/blob/main/Topology_Demands.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7C_CUG5p02E",
        "outputId": "d780587e-612e-4c99-cdaa-e00796e72e3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.5)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ],
      "source": [
        "pip install networkx openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as netx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "from scipy.stats import spearmanr\n",
        "from networkx import *\n",
        "\n",
        "def csv_to_graph(path, demands_path):\n",
        "  Df = pd.read_csv(path, header=None, names = ['id', 'source', 'target', 'length'])\n",
        "  Demands = pd.read_csv(demands_path, header=None, names = ['id', 'source', 'target', 'bitrate'])\n",
        "  df = Df.iloc[1:].copy()\n",
        "  demands = Demands.iloc[1:].copy()\n",
        "  df['source'] = df['source'].astype(int)\n",
        "  df['target'] = df['target'].astype(int)\n",
        "  df['length'] = df['length'].astype(float)\n",
        "  demands['source'] = demands['source'].astype(int)\n",
        "  demands['target'] = demands['target'].astype(int)\n",
        "  demands['bitrate'] = demands['bitrate'].astype(int) // 100\n",
        "  demands_grouped = demands.groupby(['source', 'target']).sum().reset_index()\n",
        "\n",
        "  sources = df['source'].tolist()\n",
        "  targets = df['target'].tolist()\n",
        "  lengths = df['length'].tolist()\n",
        "\n",
        "  unique_vertices = set()\n",
        "  for source, target in zip(sources, targets):\n",
        "    unique_vertices.add(source)\n",
        "    unique_vertices.add(target)\n",
        "  vertex_mapping = {old: new for new, old in enumerate(unique_vertices)}\n",
        "  num_vertices = len(unique_vertices)\n",
        "\n",
        "  adj_matrix = np.zeros((num_vertices, num_vertices))\n",
        "  demand_matrix = np.zeros((num_vertices, num_vertices))\n",
        "\n",
        "  for source, target, length in zip(sources, targets, lengths):\n",
        "    new_source = vertex_mapping[source]\n",
        "    new_target = vertex_mapping[target]\n",
        "    adj_matrix[new_source, new_target] = length\n",
        "    adj_matrix[new_target, new_source] = length\n",
        "\n",
        "  demands_grouped['source'] = demands_grouped['source'].map(vertex_mapping)\n",
        "  demands_grouped['target'] = demands_grouped['target'].map(vertex_mapping)\n",
        "  for _, row in demands_grouped.iterrows():\n",
        "    demand_matrix[row['source'], row['target']] = row['bitrate']\n",
        "\n",
        "  nodes_params = []\n",
        "\n",
        "  degrees = list(np.count_nonzero(adj_matrix, axis=1))\n",
        "  nodes_params.append(degrees)\n",
        "\n",
        "  source_demands = list(np.sum(demand_matrix, axis=1))\n",
        "  nodes_params.append(source_demands)\n",
        "\n",
        "  target_demands = list(np.sum(demand_matrix, axis=0))\n",
        "  nodes_params.append(target_demands)\n",
        "\n",
        "  return (adj_matrix, demand_matrix, nodes_params)\n",
        "\n",
        "def graph_topology(main_graph):\n",
        "  topology = []\n",
        "  if netx.is_connected(main_graph):\n",
        "    graph = main_graph\n",
        "  else:\n",
        "    components = list(netx.connected_components(main_graph))\n",
        "    largest_component = max(components, key=len)\n",
        "    graph = main_graph.subgraph(largest_component)\n",
        "\n",
        "  num_nodes = graph.number_of_nodes()\n",
        "  topology.append(num_nodes)\n",
        "\n",
        "  num_edges = graph.number_of_edges()\n",
        "  topology.append(num_edges)\n",
        "\n",
        "  degrees = graph.degree()\n",
        "  avg_degree = np.mean(graph.degree(), axis = 0)[1]\n",
        "  topology.append(avg_degree)\n",
        "\n",
        "  diameter = netx.diameter(graph)\n",
        "  topology.append(diameter)\n",
        "\n",
        "  avg_shortest_path_length = netx.average_shortest_path_length(graph)\n",
        "  topology.append(avg_shortest_path_length)\n",
        "\n",
        "  avg_clustering_coefficient = netx.average_clustering(graph)\n",
        "  topology.append(avg_clustering_coefficient)\n",
        "\n",
        "  local_clustering = list(netx.clustering(graph).values())\n",
        "  std_clustering_coefficient = np.std(local_clustering)\n",
        "  topology.append(std_clustering_coefficient)\n",
        "\n",
        "  node_betweenness = list(netx.betweenness_centrality(graph).values())\n",
        "  min_node_betweenness = min(node_betweenness)\n",
        "  topology.append(min_node_betweenness)\n",
        "  max_node_betweenness = max(node_betweenness)\n",
        "  topology.append(max_node_betweenness)\n",
        "  avg_node_betweenness = sum(node_betweenness) / num_nodes\n",
        "  topology.append(avg_node_betweenness)\n",
        "\n",
        "  edge_betweenness = list(netx.edge_betweenness_centrality(graph).values())\n",
        "  min_edge_betweenness = min(edge_betweenness)\n",
        "  topology.append(min_edge_betweenness)\n",
        "  max_edge_betweenness = max(edge_betweenness)\n",
        "  topology.append(max_edge_betweenness)\n",
        "  avg_edge_betweenness = sum(edge_betweenness) / num_edges\n",
        "  topology.append(avg_edge_betweenness)\n",
        "\n",
        "  return topology\n",
        "\n",
        "def statistic_dataframe(base_path):\n",
        "  Output = []\n",
        "  csv_tables = []\n",
        "  for folder_name in os.listdir(base_path):\n",
        "    folder_path = os.path.join(base_path, folder_name)\n",
        "    csv_path = os.path.join(folder_path, 'links.csv')\n",
        "    csv_path_demands = os.path.join(folder_path, 'demands.csv')\n",
        "    csv_tables.append(folder_name)\n",
        "\n",
        "    adj_matrix = csv_to_graph(csv_path, csv_path_demands)\n",
        "    graph = netx.from_numpy_array(adj_matrix)\n",
        "\n",
        "    Output.append(graph_topology(graph))\n",
        "\n",
        "  labels = ['Number of Nodes', 'Number of Edges', 'Average Node Degree', 'Diameter(hops)', 'Average Shortest Path Length (Hops)', 'Average Clustering Coefficient', 'Standard Deviation of Clustering Coefficient', 'Minimum Node Betweenness Centrality', 'Maximum Node Betweenness Centrality', 'Average Node Betweenness Centrality', 'Minimum Edge Betweenness Centrality', 'Maximum Edge Betweenness Centrality', 'Average Edge Betweenness Centrality']\n",
        "  Table = pd.DataFrame(Output, index = csv_tables ,columns = labels)\n",
        "\n",
        "  return Table\n",
        "\n",
        "def demands_analysis(base_path):\n",
        "  Output = []\n",
        "  csv_tables = []\n",
        "  for folder_name in os.listdir(base_path):\n",
        "    folder_path = os.path.join(base_path, folder_name)\n",
        "    csv_path = os.path.join(folder_path, 'links.csv')\n",
        "    csv_path_demands = os.path.join(folder_path, 'demands.csv')\n",
        "    csv_tables.append(folder_name)\n",
        "\n",
        "    (adj_matrix, demand_matrix, nodes_params) = csv_to_graph(csv_path, csv_path_demands)\n",
        "    degrees = nodes_params[0]\n",
        "    source_demands = nodes_params[1]\n",
        "    target_demands = nodes_params[2]\n",
        "\n",
        "    tar_corr, tar_p_value = spearmanr(degrees, target_demands)\n",
        "    src_corr, src_p_value = spearmanr(degrees, source_demands)\n",
        "\n",
        "    output = [round(tar_corr, 3), round(tar_p_value, 3), round(src_corr , 3), round(src_p_value,3)]\n",
        "    Output.append(output)\n",
        "\n",
        "  labels = ['Target Spearman Corr', 'Target Spearman P-Value', 'Source Spearman Corr', 'Source Spearman P-Value']\n",
        "  Table = pd.DataFrame(Output, index = csv_tables ,columns = labels)\n",
        "\n",
        "  return Table\n",
        "\n",
        "\n",
        "def excel(dataframe, file_name):\n",
        "  dataframe.to_excel(f'{file_name}.xlsx', index = True)\n",
        "  files.download(f'{file_name}.xlsx')\n",
        "\n",
        "path_to_folder = '/content/drive/MyDrive/Кола'\n",
        "#demands_analysis(path_to_folder)\n",
        "excel(demands_analysis(path_to_folder), 'Degree_demands_corr')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-EAmochnqFSW",
        "outputId": "8685a054-b84d-434f-cfb4-566c43455203"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0a2c5e93-6db9-49db-823a-f0b35b3008d4\", \"Degree_demands_corr.xlsx\", 5474)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}