{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/Karasiari/Graphs/blob/main/ForExps.ipynb",
      "authorship_tag": "ABX9TyOQY2vnpQRMwH1MO2by0nEY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karasiari/Graphs/blob/main/Exps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENoRVLP4h9VM",
        "outputId": "3df09ec0-950b-4476-f697-28f5a5a0c0ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/Karasiari/graphmcfexps.git\n",
            "  Cloning https://github.com/Karasiari/graphmcfexps.git to /tmp/pip-req-build-cs0rv47a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Karasiari/graphmcfexps.git /tmp/pip-req-build-cs0rv47a\n",
            "  Resolved https://github.com/Karasiari/graphmcfexps.git to commit 8a0ebe207142f17cd2ad16a33722956efceb7acd\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from graphmcfexps==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.12/dist-packages (from graphmcfexps==0.1.0) (1.16.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from graphmcfexps==0.1.0) (3.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.12/dist-packages (from graphmcfexps==0.1.0) (3.10.0)\n",
            "Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.12/dist-packages (from graphmcfexps==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->graphmcfexps==0.1.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->graphmcfexps==0.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->graphmcfexps==0.1.0) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->graphmcfexps==0.1.0) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->graphmcfexps==0.1.0) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->graphmcfexps==0.1.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->graphmcfexps==0.1.0) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->graphmcfexps==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5->graphmcfexps==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5->graphmcfexps==0.1.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->graphmcfexps==0.1.0) (1.17.0)\n",
            "Building wheels for collected packages: graphmcfexps\n",
            "  Building wheel for graphmcfexps (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graphmcfexps: filename=graphmcfexps-0.1.0-py3-none-any.whl size=11507 sha256=5bb48be5811ed0fb560e84643bae864b9e0cfbac5a909ef6dc91e44d248e2baa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7h7bs4yt/wheels/09/cf/d5/20f73fe3b91fddd32c1c90d1bb788e0d83851f63661cafc4ad\n",
            "Successfully built graphmcfexps\n",
            "Installing collected packages: graphmcfexps\n",
            "Successfully installed graphmcfexps-0.1.0\n"
          ]
        }
      ],
      "source": [
        "%pip install \"git+https://github.com/Karasiari/graphmcfexps.git\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os # Выберите, откуда тяните папку\n",
        "from google.colab import files\n",
        "\n",
        "BITRATE_DENOMINATOR = 100\n",
        "\n",
        "# По папке формируем словарь графов со структурой -\n",
        "#                                                {'название графа (как в папке)':\n",
        "#                                                       {'adj_edges': список мультиребер смежности со значением capacity мультиребра,\n",
        "#                                                        'traffic_edges': список мультребер запросов со значением weight мультиребра,\n",
        "#                                                }\n",
        "\n",
        "def csv_to_graph(path, demands_path, capacity_path):\n",
        "  Df = pd.read_csv(path, header=None, names = ['id', 'source', 'target', 'length'])\n",
        "  Traffic = pd.read_csv(demands_path, header=None, names = ['id', 'source', 'target', 'bitrate'])\n",
        "  Capacity = pd.read_csv(capacity_path, header=None, names = ['name', 'value'])\n",
        "  df = Df.iloc[1:].copy()\n",
        "  traffic = Traffic.iloc[1:].copy()\n",
        "  capacity = Capacity.iloc[1:].copy()\n",
        "\n",
        "  df['source'] = df['source'].astype(int)\n",
        "  df['target'] = df['target'].astype(int)\n",
        "  traffic['source'] = traffic['source'].astype(int)\n",
        "  traffic['target'] = traffic['target'].astype(int)\n",
        "  traffic['bitrate'] = traffic['bitrate'].astype(int) // BITRATE_DENOMINATOR\n",
        "  capacity_value = (float(capacity[capacity['name']=='LineRate']['value']) // BITRATE_DENOMINATOR) * int(capacity[capacity['name']=='NumberOfWavelengths']['value'])\n",
        "\n",
        "  sources = df['source'].tolist()\n",
        "  targets = df['target'].tolist()\n",
        "  sources_traffic = traffic['source'].tolist()\n",
        "  targets_traffic = traffic['target'].tolist()\n",
        "  bitrates_traffic = traffic['bitrate'].tolist()\n",
        "\n",
        "  unique_vertices = set()\n",
        "  for source, target in zip(sources, targets):\n",
        "    unique_vertices.add(source)\n",
        "    unique_vertices.add(target)\n",
        "  vertex_mapping = {old: new for new, old in enumerate(unique_vertices)}\n",
        "  num_vertices = len(unique_vertices)\n",
        "\n",
        "  adj_edges = []\n",
        "  traffic_edges = []\n",
        "\n",
        "  for source, target in zip(sources, targets):\n",
        "    new_source = vertex_mapping[source]\n",
        "    new_target = vertex_mapping[target]\n",
        "    adj_edges.append((new_source, new_target, {\"capacity\": capacity_value}))\n",
        "  for source, target, bitrate in zip(sources_traffic, targets_traffic, bitrates_traffic):\n",
        "    new_source = vertex_mapping[source]\n",
        "    new_target = vertex_mapping[target]\n",
        "    traffic_edges.append((new_source, new_target, {\"weight\": bitrate}))\n",
        "\n",
        "  return (adj_edges, traffic_edges)\n",
        "\n",
        "def get_graphs(base_path, specified_graphs, specified):\n",
        "  Graphs = {}\n",
        "  csv_tables = []\n",
        "  for folder_name in os.listdir(base_path):\n",
        "    if folder_name in specified_graphs or not specified:\n",
        "      folder_path = os.path.join(base_path, folder_name)\n",
        "      csv_path = os.path.join(folder_path, 'links.csv')\n",
        "      csv_path_demands = os.path.join(folder_path, 'demands.csv')\n",
        "      csv_path_capacity = os.path.join(folder_path, 'params.csv')\n",
        "      csv_tables.append(folder_name)\n",
        "\n",
        "      (adj_edges, traffic_edges) = csv_to_graph(csv_path, csv_path_demands, csv_path_capacity)\n",
        "      Graphs[folder_name] = {'adj_edges': adj_edges, 'traffic_edges': traffic_edges}\n",
        "\n",
        "  return Graphs\n",
        "\n",
        "path_to_folder = '/content/drive/MyDrive/Кола' # Свой путь"
      ],
      "metadata": {
        "id": "JlxvgaXxiMPv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "UBrJPAXJQDXh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "from graphmcfexps.expand_test import *\n",
        "\n",
        "def hu_to_graphs(adj_edges, traffic_edges):\n",
        "  adj_graph = nx.MultiGraph()\n",
        "  adj_graph.add_edges_from(adj_edges)\n",
        "  traffic_graph = nx.MultiDiGraph()\n",
        "  traffic_graph.add_nodes_from(range(adj_graph.number_of_nodes()))\n",
        "  traffic_graph.add_edges_from(traffic_edges)\n",
        "  Graph = GraphMCFexps(adj_graph, traffic_graph)\n",
        "  med_capacity = np.median([edge[2][\"capacity\"] for edge in adj_edges])\n",
        "\n",
        "  return Graph, med_capacity\n",
        "\n",
        "print(f'Доступные типы на распределение ресурсов: {get_available_types()}\\n')\n",
        "graphs_for_test_names = ['cola_t3', 'cola_t10', 'cola_t2', 'cola_t8', '2024_north', '2024_south', '2024_southwest']\n",
        "graphs_for_test = get_graphs(path_to_folder, graphs_for_test_names, True)\n",
        "for name, graph in graphs_for_test.items():\n",
        "  adj_edges, traffic_edges = graph['adj_edges'], graph['traffic_edges']\n",
        "  Graph, med_capacity = hu_to_graphs(adj_edges, traffic_edges)\n",
        "  number_to_add = 4\n",
        "  print(f'Добавим {number_to_add} новых мультиребер с capacity={med_capacity}\\n')\n",
        "  additional_capacities = [med_capacity] * number_to_add\n",
        "\n",
        "  results = []\n",
        "  for type in get_available_types():\n",
        "    gamma = expand_network_test(additional_capacities, Graph, type, alpha_type=\"min_Lalpha\") # здесь основная функция\n",
        "    results.append((type, gamma))\n",
        "  print(f'Для графа {name} результаты теста:\\n{'\\n'.join([str(type)+\": \"+str(gamma) for type, gamma in results])}\\n')"
      ],
      "metadata": {
        "id": "w7OZm1R5Jgj0",
        "outputId": "1bd7e5a7-23e6-436a-867c-5a7db2c12f6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Доступные типы на распределение ресурсов: ['initial', 'alpha', 'random', 'min_cut', 'min_Lalpha_cut', 'betweenness_unweighted']\n",
            "\n",
            "Добавим 4 новых мультиребер с capacity=80.0\n",
            "\n",
            "Для графа cola_t10 результаты теста:\n",
            "initial: 1.9999999996333915\n",
            "alpha: 1.9999999993560773\n",
            "random: 1.9999999988443715\n",
            "min_cut: 1.9999999983635477\n",
            "min_Lalpha_cut: 1.9999999992812916\n",
            "betweenness_unweighted: 1.9999999993519073\n",
            "\n",
            "Добавим 4 новых мультиребер с capacity=80.0\n",
            "\n",
            "Для графа cola_t3 результаты теста:\n",
            "initial: 1.2698412697100192\n",
            "alpha: 1.2820512819763026\n",
            "random: 1.269841269816469\n",
            "min_cut: 1.2698412696803374\n",
            "min_Lalpha_cut: 1.2698412697690167\n",
            "betweenness_unweighted: 1.2698412684229008\n",
            "\n",
            "Добавим 4 новых мультиребер с capacity=80.0\n",
            "\n",
            "Для графа cola_t8 результаты теста:\n",
            "initial: 14.285714285295352\n",
            "alpha: 15.384615382861192\n",
            "random: 14.285714275188647\n",
            "min_cut: 14.285714271894557\n",
            "min_Lalpha_cut: 14.285714285119678\n",
            "betweenness_unweighted: 14.28571426576951\n",
            "\n",
            "Добавим 4 новых мультиребер с capacity=80.0\n",
            "\n",
            "Для графа cola_t2 результаты теста:\n",
            "initial: 3.2520325195036253\n",
            "alpha: 3.252032518785877\n",
            "random: 3.2520325195770754\n",
            "min_cut: 3.2520325200925044\n",
            "min_Lalpha_cut: 3.2520325201293003\n",
            "betweenness_unweighted: 3.5714285710834304\n",
            "\n",
            "Добавим 4 новых мультиребер с capacity=320.0\n",
            "\n",
            "Для графа 2024_southwest результаты теста:\n",
            "initial: 8.421052631406596\n",
            "alpha: 8.421052631356629\n",
            "random: 8.42105263142395\n",
            "min_cut: 8.421052631439\n",
            "min_Lalpha_cut: 8.421052631427646\n",
            "betweenness_unweighted: 8.421052631410621\n",
            "\n",
            "Добавим 4 новых мультиребер с capacity=320.0\n",
            "\n",
            "Для графа 2024_south результаты теста:\n",
            "initial: 10.135746606003973\n",
            "alpha: 11.360946745134873\n",
            "random: 10.135746606105027\n",
            "min_cut: 10.135746606093123\n",
            "min_Lalpha_cut: 10.135746605872056\n",
            "betweenness_unweighted: 10.135746605325487\n",
            "\n",
            "Добавим 4 новых мультиребер с capacity=320.0\n",
            "\n",
            "Для графа 2024_north результаты теста:\n",
            "initial: 14.712643677958688\n",
            "alpha: 14.712643677988122\n",
            "random: 14.883720924540746\n",
            "min_cut: 14.712643677215691\n",
            "min_Lalpha_cut: 14.712643677996846\n",
            "betweenness_unweighted: 14.712643668539128\n",
            "\n"
          ]
        }
      ]
    }
  ]
}